{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40c0857",
   "metadata": {},
   "source": [
    "# Generate Query - LLM Powered Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0474e",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1afacd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.prompts import RichPromptTemplate\n",
    "import strawberry\n",
    "from backend.db.example_nodes import EXAMPLE_NODES\n",
    "from backend.core.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cb084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6bce834",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHQL_SCHEMA_STR = \"\"\"input FilterInput {\n",
    "  field: String!\n",
    "  operation: FilterOperator!\n",
    "  value: VALUE!\n",
    "}\n",
    "\n",
    "enum FilterOperator {\n",
    "  EQ\n",
    "  GT\n",
    "  GTE\n",
    "  LT\n",
    "  LTE\n",
    "  NEQ\n",
    "}\n",
    "\n",
    "input LogicalFilterInput {\n",
    "  and_: [LogicalFilterInput!] = null\n",
    "  or_: [LogicalFilterInput!] = null\n",
    "  not_: LogicalFilterInput = null\n",
    "  filter: FilterInput = null\n",
    "}\n",
    "\n",
    "type Mutation {\n",
    "  createUser(name: String!, email: String!, profile: ProfileInput = null): User!\n",
    "  updateUser(id: ID!, name: String = null, email: String = null, profile: ProfileInput = null): User!\n",
    "  deleteUser(id: ID!): User!\n",
    "  createProduct(name: String!, price: Float!): Product!\n",
    "  updateProduct(id: ID!, name: String = null, price: Float = null): Product!\n",
    "  deleteProduct(id: ID!): Product!\n",
    "  createOrder(userId: String!, items: [OrderItemInput!]!, status: OrderStatus!): Order!\n",
    "  updateOrder(id: ID!, userId: String = null, items: [OrderItemInput!] = null, status: OrderStatus = null): Order!\n",
    "  deleteOrder(id: ID!): Order!\n",
    "  createReview(productId: String!, userId: String!, rating: Int!, comment: String = null): Review!\n",
    "}\n",
    "\n",
    "type Order {\n",
    "  id: ID!\n",
    "  items: [OrderItem!]\n",
    "  status: OrderStatus\n",
    "  user: User\n",
    "}\n",
    "\n",
    "type OrderItem {\n",
    "  quantity: Int\n",
    "  product: Product\n",
    "}\n",
    "\n",
    "input OrderItemInput {\n",
    "  productId: String!\n",
    "  quantity: Int!\n",
    "}\n",
    "\n",
    "enum OrderStatus {\n",
    "  PENDING\n",
    "  ORDERED\n",
    "  SHIPPED\n",
    "  DELIVERED\n",
    "  CANCELLED\n",
    "}\n",
    "\n",
    "type Product {\n",
    "  id: ID!\n",
    "  name: String\n",
    "  price: Float\n",
    "  reviews: [Review!]\n",
    "}\n",
    "\n",
    "type Profile {\n",
    "  age: Int\n",
    "  location: String\n",
    "}\n",
    "\n",
    "input ProfileInput {\n",
    "  age: Int!\n",
    "  location: String!\n",
    "}\n",
    "\n",
    "type Query {\n",
    "  users(filters: LogicalFilterInput = null): [User!]!\n",
    "  orders(filters: LogicalFilterInput = null): [Order!]!\n",
    "  products(filters: LogicalFilterInput = null): [Product!]!\n",
    "  reviews(filters: LogicalFilterInput = null): [Review!]!\n",
    "  user(id: ID!): User!\n",
    "  order(id: ID!): Order!\n",
    "  product(id: ID!): Product!\n",
    "}\n",
    "\n",
    "type Review {\n",
    "  id: ID!\n",
    "  rating: Int\n",
    "  comment: String\n",
    "  createdAt: String\n",
    "  product: Product\n",
    "  user: User\n",
    "}\n",
    "\n",
    "type User {\n",
    "  id: ID!\n",
    "  name: String\n",
    "  email: String\n",
    "  profile: Profile\n",
    "  orders: [Order!]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489e9a2",
   "metadata": {},
   "source": [
    "## LLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aed8d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "index = VectorStoreIndex(nodes=EXAMPLE_NODES)\n",
    "retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0938c",
   "metadata": {},
   "source": [
    "## Prompt Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396483a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_STR = \"\"\"\n",
    "You are a GraphQL expert. You are an assistant that converts natural language\n",
    "queries into GraphQL queries. You must strictly follow the provided\n",
    "GraphQL schema and generate queries based on it.\n",
    "\n",
    "Here is the GraphQL schema you should use:\n",
    "<schema>\n",
    "{{ schema }}\n",
    "</schema>\n",
    "\n",
    "Here are some examples of how you should convert natural language to GraphQL:\n",
    "<examples>\n",
    "{{ examples }}\n",
    "</examples>\n",
    "\n",
    "Now it's your turn.\n",
    "\n",
    "Query: {{ query_str }}\n",
    "GraphQL:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_examples_fn(**kwargs):\n",
    "    \"\"\"Retrieve relevant examples based on the input query.\"\"\"\n",
    "    query = kwargs[\"query_str\"]\n",
    "    examples = retriever.retrieve(query)\n",
    "    return \"\\n\\n\".join(node.text for node in examples)\n",
    "\n",
    "\n",
    "prompt_template = RichPromptTemplate(\n",
    "    PROMPT_TEMPLATE_STR,\n",
    "    function_mappings={\"examples\": get_examples_fn},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9d1d9",
   "metadata": {},
   "source": [
    "## Generate GraphQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3620ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_graphql_query(\n",
    "    natural_language_query: str, schema: str\n",
    ") -> str:\n",
    "    \"\"\"Generate a GraphQL query using dynamic few-shot prompting.\"\"\"\n",
    "    prompt = prompt_template.format(\n",
    "        query_str=natural_language_query,\n",
    "        schema=schema,\n",
    "    )\n",
    "    # print(f\"Prompt: \\n {prompt}\")\n",
    "    llm = Settings.llm\n",
    "    response = await llm.acomplete(prompt)\n",
    "    return response.text.strip(\"```\").strip(\"graphql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e90680",
   "metadata": {},
   "source": [
    "## Validate and Execute GraphQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b609f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_and_execute_query(\n",
    "    graphql_query: str, schema: strawberry.Schema\n",
    "):\n",
    "    \"\"\"Validate and execute the GraphQL query.\"\"\"\n",
    "    result = await schema.execute(graphql_query)\n",
    "    if result.errors:\n",
    "        raise ValueError(f\"GraphQL execution errors: {result.errors}\")\n",
    "    return result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ae028",
   "metadata": {},
   "source": [
    "## Test the Generation of GraphQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92c0465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated GraphQL query: \n",
      "Please provide your natural language query so I can convert it into a GraphQL query according to the schema.\n"
     ]
    }
   ],
   "source": [
    "user_query = input(\"Enter a query: \")\n",
    "print(\n",
    "    \"Generated GraphQL query: \\n\"\n",
    "    f\"{await generate_graphql_query(user_query, GRAPHQL_SCHEMA_STR)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26efc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
